{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop week 2 Vasil Stamenkoski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop we will compare all classifiers from the past 2 weeeks that we learned about so far with the diabetes dataset and try to find the best possible model parameters. \n",
    "<br><br>\n",
    "1. Make a 5Fold CV.\n",
    "<br><br>\n",
    "2. Fit a dummy classifier.\n",
    "<br><br>\n",
    "3. Fit a Gaussian Naive Bayes classifier.\n",
    "<br><br>\n",
    "4. Fit a KNN classifier. Do a grid search to find optimal parameters 'n_neighbors' in range of 1 to 50. Once you find optimal K refit a model with those parameters on X_train, y_train.\n",
    "<br><br>\n",
    "5. Fit a Decision tree classifier. Find optimal parameter values for 'max_depth' in range of 1 to 10. Once you find optimal max_depth refit a model with those parameters on X_train, y_train.\n",
    "<br><br>\n",
    "6. Fit a support vector classifier. Try to find optimal parameter values for the following 3 parameters. For kernel try ['rbf', 'sigmoid'], for the soft margin parameter C try [0.1, 1, 10, 100] and for the gamma parameter try [1,0.1,0.01,0.001] (the gamma parameter defines how far the influence of a single training example reaches). Once you find optimal parameters refit a model with those parameters on X_train, y_train.\n",
    "<br><br>\n",
    "7. Fit Random Forest Classifier with default parameters.\n",
    "<br><br>\n",
    "8. Fit BaggingClassifier with base_estimator=DecisionTreeClassifier().\n",
    "<br><br>\n",
    "9. Fit AdaBoostClassifier with base_estimator=DecisionTreeClassifier().\n",
    "<br><br>\n",
    "10. Fit Voting Classifier with 'DecisionTreeClassifier(), SVC(degree=2, kernel='poly') and Gaussian Naive Bayes. (or try your own Vote Classifier)\n",
    "<br><br>\n",
    "11. Optional: Try Voting(weighted), Stacking, Boosting algorithm.\n",
    "\n",
    "<br><br>\n",
    "12. **Summary:** Compare and discuss the results, compare the f1_score of all the best models on the KFold CV, analyze the classification report. \n",
    "<br>\n",
    "*Note:* Use random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For performing train/test/split\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "# import all the models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# For computing accuracy score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS AND FLAGS\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset info\n",
    "<br>\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "<br><br>\n",
    "Content<br>\n",
    "The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "<br><br>\n",
    "Acknowledgements<br>\n",
    "Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg   plas  pres  skin   insu  mass   pedi   age\n",
       "0     6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0\n",
       "1     1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0\n",
       "2     8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0\n",
       "3     1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0\n",
       "4     0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0\n",
       "..    ...    ...   ...   ...    ...   ...    ...   ...\n",
       "763  10.0  101.0  76.0  48.0  180.0  32.9  0.171  63.0\n",
       "764   2.0  122.0  70.0  27.0    0.0  36.8  0.340  27.0\n",
       "765   5.0  121.0  72.0  23.0  112.0  26.2  0.245  30.0\n",
       "766   1.0  126.0  60.0   0.0    0.0  30.1  0.349  47.0\n",
       "767   1.0   93.0  70.0  31.0    0.0  30.4  0.315  23.0\n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# drop the unwanted columns\n",
    "df.drop(['Unnamed: 0', 'id'], axis='columns', inplace=True)\n",
    "\n",
    "# set our target vector\n",
    "y = df['class']\n",
    "\n",
    "# set our feature columns\n",
    "X = df.drop('class', axis='columns')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    500\n",
      "1    268\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# see how balanced our data is\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our KFold class\n",
    "kf = StratifiedKFold(n_splits=N_SPLITS, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64935065 0.64935065 0.64935065 0.65359477 0.65359477]\n",
      "0.6510482981071216\n",
      "[0. 0. 0. 0. 0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# DUMMY MODEL\n",
    "pipeline = Pipeline([('mms', MinMaxScaler()), ('clf', DummyClassifier())])\n",
    "\n",
    "rez_acc = cross_val_score(pipeline, X, y, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "print(rez_acc)\n",
    "print(np.mean(rez_acc))\n",
    "\n",
    "rez_f1 = cross_val_score(pipeline, X, y, cv=kf, scoring=make_scorer(f1_score))\n",
    "print(rez_f1)\n",
    "print(np.mean(rez_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64935065 0.64935065 0.64935065 0.65359477 0.65359477]\n",
      "0.6510482981071216\n",
      "[0. 0. 0. 0. 0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# BASELINE MODEL\n",
    "pipeline = Pipeline([('mms', MinMaxScaler()), ('clf', DummyClassifier())])\n",
    "\n",
    "rez_acc = cross_val_score(pipeline, X, y, cv=kf, scoring=make_scorer(accuracy_score))\n",
    "print(rez_acc)\n",
    "print(np.mean(rez_acc))\n",
    "\n",
    "rez_f1 = cross_val_score(pipeline, X, y, cv=kf, scoring=make_scorer(f1_score))\n",
    "print(rez_f1)\n",
    "print(np.mean(rez_f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65979381 0.67326733 0.65306122 0.59793814 0.62135922]\n",
      "0.6410839466572653\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('mms', MinMaxScaler()), ('clf', RandomForestClassifier(max_depth=10, n_estimators=100, criterion='gini', max_samples=0.67, random_state=RANDOM_STATE))])\n",
    "\n",
    "rez_f1 = cross_val_score(pipeline, X, y, cv=kf, scoring=make_scorer(f1_score))\n",
    "print(rez_f1)\n",
    "print(np.mean(rez_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# Perform grid search with 5-fold cross validation\u001b[39;00m\n\u001b[0;32m     14\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(knn, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m grid\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     17\u001b[0m \u001b[39m# Find the optimal number of neighbors\u001b[39;00m\n\u001b[0;32m     18\u001b[0m optimal_k \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39mbest_params_[\u001b[39m'\u001b[39m\u001b[39mn_neighbors\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "##Fit a KNN classifier. Do a grid search to find optimal parameters 'n_neighbors' in range of 1 to 50. \n",
    "#Once you find optimal K refit a model with those parameters on X_train, y_train.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {'n_neighbors': range(1, 51)}\n",
    "\n",
    "# Perform grid search with 5-fold cross validation\n",
    "grid = GridSearchCV(knn, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Find the optimal number of neighbors\n",
    "optimal_k = grid.best_params_['n_neighbors']\n",
    "\n",
    "# Refit the model with optimal number of neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy score on the training data\n",
    "print('Accuracy on training data:', knn.score(X_train, y_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 8}\n",
      "Accuracy on training data: 0.7768729641693811\n"
     ]
    }
   ],
   "source": [
    "##Fit same model ffrom above with pipeline\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([('knn', KNeighborsClassifier())])\n",
    "\n",
    "# Create a dictionary of parameters to search over\n",
    "param_grid = {'knn__n_neighbors': range(1,51)}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best value of n_neighbors found\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Access the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the accuracy score on the training data\n",
    "print('Accuracy on training data:', knn.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal max_depth value:  {'max_depth': 3}\n",
      "Accuracy on training data: 0.7768729641693811\n"
     ]
    }
   ],
   "source": [
    "#5. Fit a Decision tree classifier. Find optimal parameter values for 'max_depth' in range of 1 to 10. \n",
    "#Once you find optimal max_depth refit a model with those parameters on X_train, y_train.\n",
    "\n",
    "# Create the Decision Tree classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Specify the parameter grid for max_depth\n",
    "param_grid = {'max_depth': range(1, 11)}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal max_depth value\n",
    "print(\"Optimal max_depth value: \", grid_search.best_params_)\n",
    "\n",
    "# Create the Decision Tree classifier with optimal max_depth\n",
    "dt = DecisionTreeClassifier(max_depth=grid_search.best_params_['max_depth'])\n",
    "\n",
    "# Fit the Decision Tree classifier to the training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy on training data:', dt.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;dt&#x27;, DecisionTreeClassifier(max_depth=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;dt&#x27;, DecisionTreeClassifier(max_depth=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('dt', DecisionTreeClassifier(max_depth=3))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Fit a Decision tree classifier. Find optimal parameter values for 'max_depth' in range of 1 to 10. \n",
    "#Once you find optimal max_depth refit a model with those parameters on X_train, y_train with pipeline\n",
    "\n",
    "# Initialize the decision tree classifier with the optimal max_depth\n",
    "dt = DecisionTreeClassifier(max_depth=grid_search.best_params_['max_depth'])\n",
    "\n",
    "# Create a pipeline with the decision tree classifier\n",
    "pipe = Pipeline([('dt', dt)])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.8550488599348535\n"
     ]
    }
   ],
   "source": [
    "#Fit a support vector classifier. Try to find optimal parameter values for the following 3 parameters. \n",
    "#For kernel try ['rbf', 'sigmoid'], for the soft margin parameter C try [0.1, 1, 10, 100] and for the gamma parameter try [1,0.1,0.01,0.001].\n",
    "# Once you find optimal parameters refit a model with those parameters on X_train, y_train\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "svc = SVC()\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {'kernel': ['rbf', 'sigmoid'], 'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001]}\n",
    "\n",
    "# Perform grid search with 5-fold cross validation\n",
    "grid = GridSearchCV(svc, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Find the optimal parameters\n",
    "optimal_kernel = grid.best_params_['kernel']\n",
    "optimal_C = grid.best_params_['C']\n",
    "optimal_gamma = grid.best_params_['gamma']\n",
    "\n",
    "# Refit the model with optimal parameters\n",
    "svc = SVC(kernel=optimal_kernel, C=optimal_C, gamma=optimal_gamma)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy score on the training data\n",
    "print('Accuracy on training data:', svc.score(X_train, y_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_samples_leaf=5, min_samples_split=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_leaf=5, min_samples_split=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=5, min_samples_split=5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_rf = RandomForestClassifier(n_estimators=100,max_depth=None,min_samples_split=5,min_samples_leaf=5,max_features='sqrt',max_leaf_nodes=None)\n",
    "classifier_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = classifier_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest is: 0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy for Random Forest is:\",metrics.accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83        99\n",
      "           1       0.69      0.65      0.67        55\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.75      0.75       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055374592833876"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, classifier_rf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 16],\n",
       "       [19, 36]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "\n",
    "plt.yticks(np.arange(1))\n",
    "plt.ylabel('True labels');\n",
    "plt.xlabel('Predicted labels');\n",
    "plt.title('Confusion matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_score is: 0.8137254901960784\n",
      "recall_score is: 0.8383838383838383\n",
      "f1_score_micro is: 0.7727272727272727\n",
      "f1_score_weighted is: 0.7712372715859953\n"
     ]
    }
   ],
   "source": [
    "print('Precision_score is:', metrics.precision_score(y_test, y_pred_rf, pos_label=0))\n",
    "print('recall_score is:', metrics.recall_score(y_test, y_pred_rf, pos_label=0))\n",
    "print('f1_score_micro is:', metrics.f1_score(y_test, y_pred_rf, average='micro'))\n",
    "print('f1_score_weighted is:', metrics.f1_score(y_test, y_pred_rf, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(n_estimators=50, learning_rate=1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = abc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Model Accuracy is: 0.7337662337662337\n"
     ]
    }
   ],
   "source": [
    "print(\"AdaBoost Classifier Model Accuracy is:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(probability=True, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc =AdaBoostClassifier(n_estimators=50,estimator=svc,learning_rate=1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = abc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with SVC Base Estimator: 0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Accuracy with SVC Base Estimator:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with Bagging Clasifier is:\n",
      "0.7643229166666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "seed = 8\n",
    "kfold = model_selection.KFold(n_splits = 3,random_state = seed,shuffle=True)\n",
    " \n",
    "# initialize the base classifier\n",
    "base_cls = DecisionTreeClassifier()\n",
    " \n",
    "# no. of base classifier\n",
    "num_trees = 500\n",
    " \n",
    "# bagging classifier\n",
    "model = BaggingClassifier(estimator = base_cls,n_estimators = num_trees,random_state = seed)\n",
    " \n",
    "results = model_selection.cross_val_score(model, X, y, cv = kfold)\n",
    "print(\"Model Accuracy with Bagging Clasifier is:\")\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the voting classifier: 79.87%\n"
     ]
    }
   ],
   "source": [
    "###Voting dt & Gaus & svc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define individual classifiers\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "svc_clf = SVC(degree=2, kernel='poly', probability=True, random_state=42)\n",
    "gnb_clf = GaussianNB()\n",
    "\n",
    "# Define the voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[('dt', dt_clf), ('svc', svc_clf), ('gnb', gnb_clf)], voting='hard')\n",
    "\n",
    "# Fit the voting classifier to your training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "#Make prediction\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "#Calculate acc\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "#print acc of voting clf\n",
    "print(\"Accuracy of the voting classifier: {:.2f}%\".format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Score  0\n",
      "Soft Voting Score  0\n"
     ]
    }
   ],
   "source": [
    "###Voting dt & Gaus & svc & lr\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "estimator = []\n",
    "estimator.append(('LR', LogisticRegression(solver ='lbfgs',  multi_class ='multinomial', max_iter = 200)))\n",
    "estimator.append(('SVC', SVC(degree=2, kernel='poly', probability=True, random_state=42)))\n",
    "estimator.append(('DTC', DecisionTreeClassifier(criterion='entropy',max_depth=7,random_state=42,)))\n",
    "estimator.append(('GN',GaussianNB()))\n",
    "  \n",
    "# Voting Classifier with hard voting\n",
    "vot_hard = VotingClassifier(estimators = estimator, voting ='hard')\n",
    "vot_hard.fit(X_train, y_train)\n",
    "y_pred = vot_hard.predict(X_test)\n",
    "  \n",
    "# using accuracy_score metric to predict accuracy\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Hard Voting Score % d\" % score)\n",
    "  \n",
    "# Voting Classifier with soft voting\n",
    "vot_soft = VotingClassifier(estimators = estimator, voting ='soft')\n",
    "vot_soft.fit(X_train, y_train)\n",
    "y_pred = vot_soft.predict(X_test)\n",
    "  \n",
    "# using accuracy_score\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Soft Voting Score % d\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the weighted voting classifier: 79.87%\n",
      "Accuracy of the stacking classifier: 79.22%\n",
      "Accuracy of the graadient classifier: 74.68%\n",
      "Accuracy of the adaboost classifier: 74.68%\n"
     ]
    }
   ],
   "source": [
    "##Optional task with all the models with accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "# Define individual classifiers\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "svc_clf = SVC(degree=2, kernel='poly', probability=True, random_state=42)\n",
    "gnb_clf = GaussianNB()\n",
    "\n",
    "# Define the voting classifier with weights\n",
    "voting_clf_weights = VotingClassifier(estimators=[('dt', dt_clf), ('svc', svc_clf), ('gnb', gnb_clf)], voting='hard',weights=[5, 9, 7])\n",
    "\n",
    "# Fit the voting classifier to your training data\n",
    "voting_clf_weights.fit(X_train, y_train)\n",
    "\n",
    "# Use the voting classifier to make predictions on the test data\n",
    "y_pred_weights = voting_clf_weights.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the voting classifier\n",
    "accuracy_weights = accuracy_score(y_test, y_pred_weights)\n",
    "\n",
    "# Define the stacking classifier\n",
    "stacking_clf = StackingClassifier(estimators=[('dt', dt_clf), ('svc', svc_clf), ('gnb', gnb_clf)], final_estimator=LogisticRegression(random_state=42))\n",
    "\n",
    "# Fit the stacking classifier to your training data\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the stacking classifier to make predictions on the test data\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the stacking classifier\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "\n",
    "# Define the boosting classifier\n",
    "boosting_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the boosting classifier to your training data\n",
    "boosting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the boosting classifier to make predictions on the test data\n",
    "y_pred_boosting = boosting_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the boosting classifier\n",
    "accuracy_boosting = accuracy_score(y_test, y_pred_boosting)\n",
    "\n",
    "# Define the boosting classifier\n",
    "boosting_clf = AdaBoostClassifier(estimator=dt_clf, n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the boosting classifier to your training data\n",
    "boosting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the boosting classifier to make predictions on the test data\n",
    "y_pred_boosting = boosting_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the boosting classifier\n",
    "accuracy_boosting = accuracy_score(y_test, y_pred_boosting)\n",
    "\n",
    "\n",
    "# Print the accuracy of each algorithm\n",
    "print(\"Accuracy of the weighted voting classifier: {:.2f}%\".format(accuracy_weights * 100))\n",
    "print(\"Accuracy of the stacking classifier: {:.2f}%\".format(accuracy_stacking * 100))\n",
    "print(\"Accuracy of the graadient classifier: {:.2f}%\".format(accuracy_boosting * 100))\n",
    "print(\"Accuracy of the adaboost classifier: {:.2f}%\".format(accuracy_boosting * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score of the weighted voting classifier: 69.90%\n",
      "F1_score of the stacking classifier: 69.23%\n",
      "F1_score of the graadient classifier: 67.77%\n",
      "F1_score of the adaboost classifier: 67.77%\n"
     ]
    }
   ],
   "source": [
    "##Optional task with all the models with f1_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define individual classifiers\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "svc_clf = SVC(degree=2, kernel='poly', probability=True, random_state=42)\n",
    "gnb_clf = GaussianNB()\n",
    "\n",
    "# Define the voting classifier with weights\n",
    "voting_clf_weights = VotingClassifier(estimators=[('dt', dt_clf), ('svc', svc_clf), ('gnb', gnb_clf)], voting='hard',weights=[5, 9, 7])\n",
    "\n",
    "# Fit the voting classifier to your training data\n",
    "voting_clf_weights.fit(X_train, y_train)\n",
    "\n",
    "# Use the voting classifier to make predictions on the test data\n",
    "y_pred_weights = voting_clf_weights.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the voting classifier\n",
    "f1_weights = f1_score(y_test, y_pred_weights)\n",
    "\n",
    "# Define the stacking classifier\n",
    "stacking_clf = StackingClassifier(estimators=[('dt', dt_clf), ('svc', svc_clf), ('gnb', gnb_clf)], final_estimator=LogisticRegression(random_state=42))\n",
    "\n",
    "# Fit the stacking classifier to your training data\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the stacking classifier to make predictions on the test data\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the stacking classifier\n",
    "f1_stacking = f1_score(y_test, y_pred_stacking)\n",
    "\n",
    "# Define the boosting classifier\n",
    "boosting_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the boosting classifier to your training data\n",
    "boosting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the boosting classifier to make predictions on the test data\n",
    "y_pred_boosting = boosting_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the boosting classifier\n",
    "f1_boosting = f1_score(y_test, y_pred_boosting)\n",
    "\n",
    "# Define the boosting classifier\n",
    "boosting_clf = AdaBoostClassifier(estimator=dt_clf, n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the boosting classifier to your training data\n",
    "boosting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the boosting classifier to make predictions on the test data\n",
    "y_pred_boosting = boosting_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the boosting classifier\n",
    "f1_boosting = f1_score(y_test, y_pred_boosting)\n",
    "\n",
    "\n",
    "# Print the accuracy of each algorithm\n",
    "print(\"F1_score of the weighted voting classifier: {:.2f}%\".format(f1_weights * 100))\n",
    "print(\"F1_score of the stacking classifier: {:.2f}%\".format(f1_stacking * 100))\n",
    "print(\"F1_score of the graadient classifier: {:.2f}%\".format(f1_boosting * 100))\n",
    "print(\"F1_score of the adaboost classifier: {:.2f}%\".format(f1_boosting * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vasil Stamenkoski\n"
     ]
    }
   ],
   "source": [
    "print('Vasil Stamenkoski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
