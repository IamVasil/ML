{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mwdjskw6r4Tu"
   },
   "source": [
    "# Workshop Task - Training models and preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7LRTcrGr4Tu"
   },
   "source": [
    "We have a binary classification problem where we have to predict whether a credit should be approved or not for a new client of a bank.\n",
    "\n",
    "\n",
    "|Field Name|\tOrder|\tType (Format)|Description|\n",
    "| -------| -------|-----------|---------|\n",
    "|checking_status|\t1|\tstring (default)|Status of existing checking account, in Deutsche Mark.|\t\n",
    "|duration\t|2|\tnumber (default)\t|Duration in months|\n",
    "|credit_history\t|3|\tstring (default)\t|Credit history (credits taken, paid back duly, delays, critical accounts)|\n",
    "|purpose\t|4|\tstring (default)\t|Purpose of the credit (car, television,…)|\n",
    "|credit_amount\t|5|\tnumber (default)\t|Credit amount|\n",
    "|savings_status\t|6|\tstring (default)\t|Status of savings account/bonds, in Deutsche Mark.|\n",
    "|employment\t|7|\tstring (default)\t|Present employment, in number of years.|\n",
    "|installment_commitment\t|8|\tnumber (default)|Installment rate in percentage of disposable income|\t\n",
    "|personal_status\t|9|\tstring (default)|Personal status (married, single,…) and sex|\n",
    "|other_parties\t|10|\tstring (default)|Other debtors / guarantors|\t\n",
    "|residence_since\t|11|\tnumber (default)|Present residence since X years|\t\n",
    "|property_magnitude\t|12|\tstring (default)|Property (e.g. real estate)|\t\n",
    "|age\t|13|\tnumber (default)\t|Age in years|\n",
    "|other_payment_plans\t|14|\tstring (default)|Other installment plans (banks, stores)|\n",
    "|housing\t|15|\tstring (default)\t|Housing (rent, own,…)|\n",
    "|existing_credits\t|16|\tnumber (default)|Number of existing credits at this bank|\t\n",
    "|job\t|17|\tstring (default)\t|Job|\n",
    "|num_dependents\t|18|\tnumber (default)|Number of people being liable to provide maintenance for|\t\n",
    "|own_telephone\t|19|\tstring (default)|Telephone (yes,no)|\t\n",
    "|foreign_worker\t|20|\tstring (default)|Foreign worker (yes,no)|\t\n",
    "accepted\t|21|\tstring (default)\t|Class|\n",
    "\n",
    "\n",
    "Your task is to : \n",
    "  1. Use some EDA techniques we learned the last 2 weeks\n",
    "  2. Detect missing values\n",
    "  4. From the seaborn package use the functions displot and boxplot to plot the distributions of the numerical variables. This should give you insight into what scaling type you should use. The boxplots will give a good indication on the presence of outliers.\n",
    "\n",
    "  5. Scale the data.\n",
    "\n",
    "  6. For the categorical features try different encodings e.g. target, label... \n",
    "    \n",
    "  7. Make train/test split : with train(70%), test(30%) with random_state = 0\n",
    "\n",
    "  8. Try to build quickly a few models, a Decision Tree, a Random Forest, a polynomial SVM, a Radial Basis SVM, KNN. Try to achieve performance of 80% + on test set. \n",
    "  \n",
    "  9. Evaluate the model\n",
    "    \n",
    "  10. For reproducibility please use random_state on train_test_split and model initialization\n",
    "  \n",
    "  11. Write a summary :\n",
    "    - Which model gives the best result?\n",
    "    - What can we improve in the future?\n",
    "    - BONUs: Which encoding give better performance on this dataset?\n",
    "\n",
    "Bonus:\n",
    "- Try building a model with only a subset of features. Try any of the feature selection techniques to find the 5 most important features according to each of the methods we learned in the previous week. Write a short summary of the results.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset-workshop.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Unnamed: 0','checking_status','duration','purpose','savings_status',\n",
    "'personal_status','property_magnitude',\n",
    "'other_payment_plans','job','own_telephone'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['credit_history'] = dataset['credit_history'].map({'Critical_acct_other_credits_existing':0,'Existing_credits_paid_till_now':1,'Delay_in_past': 2,'None': 3,'No_credits_taken_or_all_paid':4,'All_credits_paid_duly':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['employment'] =dataset['employment'].map({'>7yrs':0,'1_to_4yrs':1,'4_to_7yrs':2,'unemployed':3,'<1yr':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['other_parties'] = dataset['other_parties'].map({'None':0, 'guarantor':1,'co-applicant':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['housing'] = dataset['housing'].map({'own': 0, 'for_free': 1, 'rent':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['foreign_worker'] = dataset['foreign_worker'].map({'yes': 0, 'no': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_not_accepted = ['age']\n",
    "for column in zero_not_accepted:\n",
    "    dataset[column] = dataset[column].replace(0,np.NaN)\n",
    "    mean = int(dataset[column].mean(skipna=True))\n",
    "    dataset[column] = dataset[column].replace(np.NaN,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['credit_amount','age']\n",
    "for col in cols:\n",
    "   dataset[col] = dataset[col].apply(lambda x: int(x) if x == x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(dataset,test_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(752, 12)\n",
      "(251, 12)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       credit_history  credit_amount  employment  installment_commitment  \\\n",
      "count      752.000000     752.000000  752.000000              752.000000   \n",
      "mean         1.174202    4493.726064    1.514628                2.994681   \n",
      "std          1.269419    3651.895451    1.374990                1.125884   \n",
      "min          0.000000     508.000000    0.000000                1.000000   \n",
      "25%          0.000000    1930.750000    0.000000                2.000000   \n",
      "50%          1.000000    3625.500000    1.000000                3.000000   \n",
      "75%          1.000000    5871.250000    2.000000                4.000000   \n",
      "max          5.000000   26200.000000    4.000000                4.000000   \n",
      "\n",
      "       other_parties  residence_since         age     housing  \\\n",
      "count     752.000000       752.000000  752.000000  752.000000   \n",
      "mean        0.121011         2.872340   35.507979    0.468085   \n",
      "std         0.422389         1.088461   11.057889    0.778570   \n",
      "min         0.000000         1.000000   19.000000    0.000000   \n",
      "25%         0.000000         2.000000   27.000000    0.000000   \n",
      "50%         0.000000         3.000000   34.000000    0.000000   \n",
      "75%         0.000000         4.000000   41.000000    1.000000   \n",
      "max         2.000000         4.000000   75.000000    2.000000   \n",
      "\n",
      "       existing_credits  num_dependents  foreign_worker    accepted  \n",
      "count        752.000000      752.000000      752.000000  752.000000  \n",
      "mean           1.413564        1.152926        0.038564    0.292553  \n",
      "std            0.584283        0.360155        0.192681    0.455238  \n",
      "min            1.000000        1.000000        0.000000    0.000000  \n",
      "25%            1.000000        1.000000        0.000000    0.000000  \n",
      "50%            1.000000        1.000000        0.000000    0.000000  \n",
      "75%            2.000000        1.000000        0.000000    1.000000  \n",
      "max            4.000000        2.000000        1.000000    1.000000  \n",
      "       credit_history  credit_amount  employment  installment_commitment  \\\n",
      "count      251.000000     251.000000  251.000000              251.000000   \n",
      "mean         1.314741    4534.219124    1.697211                2.908367   \n",
      "std          1.302514    3676.583876    1.392822                1.093421   \n",
      "min          0.000000     505.000000    0.000000                1.000000   \n",
      "25%          1.000000    1908.500000    1.000000                2.000000   \n",
      "50%          1.000000    3870.000000    1.000000                3.000000   \n",
      "75%          1.000000    5907.000000    3.000000                4.000000   \n",
      "max          5.000000   27389.000000    4.000000                4.000000   \n",
      "\n",
      "       other_parties  residence_since         age     housing  \\\n",
      "count     251.000000       251.000000  251.000000  251.000000   \n",
      "mean        0.171315         2.764940   35.677291    0.454183   \n",
      "std         0.504513         1.143908   11.091774    0.780316   \n",
      "min         0.000000         1.000000   19.000000    0.000000   \n",
      "25%         0.000000         2.000000   27.000000    0.000000   \n",
      "50%         0.000000         3.000000   34.000000    0.000000   \n",
      "75%         0.000000         4.000000   42.000000    1.000000   \n",
      "max         2.000000         4.000000   75.000000    2.000000   \n",
      "\n",
      "       existing_credits  num_dependents  foreign_worker    accepted  \n",
      "count        251.000000      251.000000      251.000000  251.000000  \n",
      "mean           1.386454        1.159363        0.031873    0.318725  \n",
      "std            0.556827        0.366745        0.176012    0.466913  \n",
      "min            1.000000        1.000000        0.000000    0.000000  \n",
      "25%            1.000000        1.000000        0.000000    0.000000  \n",
      "50%            1.000000        1.000000        0.000000    0.000000  \n",
      "75%            2.000000        1.000000        0.000000    1.000000  \n",
      "max            4.000000        2.000000        1.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.describe())\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns = ['accepted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['accepted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns = ['accepted']).values\n",
    "X_test = test_df.drop(columns = ['accepted']).values\n",
    "y_train = train_df['accepted'].values\n",
    "y_test = test_df['accepted'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(X_train,y_train, random_state=0, test_size=0.3, train_size=0.7)\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_test = mms.fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 372, 1: 154})\n",
      "Counter({0: 160, 1: 66})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "\n",
    "assert X_train.shape[1] == X_test.shape[1]\n",
    "assert type(y_train) == type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (526, 11)\n",
      "y_train: (526,)\n",
      "X_test: (226, 11)\n",
      "y_test: (226,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole dataset :  1003\n",
      "X Train size 526\n",
      "X Test size 226\n",
      "y train size 526\n",
      "y test size 226\n",
      "(526, 11)\n",
      "526\n"
     ]
    }
   ],
   "source": [
    "print(\"Whole dataset : \", len(train_df)+len(test_df))\n",
    "print(\"X Train size\", len(X_train))\n",
    "print(\"X Test size\", len(X_test))\n",
    "print(\"y train size\", len(y_train))\n",
    "print(\"y test size\", len(y_test))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.15678032, 0.25      , 1.        , 0.        ,\n",
       "       0.33333333, 0.07407407, 0.        , 0.33333333, 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpf = model.partial_fit(X_test,y_test, np.unique(y_test))\n",
    "mpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90       160\n",
      "           1       0.71      0.95      0.81        66\n",
      "\n",
      "    accuracy                           0.87       226\n",
      "   macro avg       0.84      0.90      0.86       226\n",
      "weighted avg       0.90      0.87      0.88       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8498098859315589"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc = SVC(kernel='rbf', C=5)\n",
    "svc = LinearSVC(C=100, max_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=100, max_iter=100000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90       160\n",
      "           1       0.70      0.94      0.81        66\n",
      "\n",
      "    accuracy                           0.87       226\n",
      "   macro avg       0.84      0.89      0.85       226\n",
      "weighted avg       0.89      0.87      0.87       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VASIL STAMENKOSKI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workshop_Week4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
